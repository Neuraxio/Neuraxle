{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Saving And Lifecycle \n",
    "\n",
    "<p style=\"font-size:18px\">This page introduces the concept of lifecycle in a Neuraxle BaseStep. You can find a deailed component API reference here.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle\n",
    "\n",
    "![Machine Learning Lifecycle in Neuraxle](./images/neuraxle_machine_learning_lifecycle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[BaseStep.__init__(hyperparams, hyperparams_space, name)](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.BaseStep)**: This is where you initialize all of your props, and fitted state. \n",
    "2. **[set_hyperparams(hyperperparams)](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base._HasHyperparams.set_hyperparams)**:\n",
    "3. **[setup(context)](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.TransformerStep.setup)**: Initialize the step before it runs. Only from here and not before that heavy things should be created (e.g.: things inside GPU), and NOT in the constructor.\n",
    "4. **[fit(data_inputs, expected_outputs)](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base._FittableStep.fit)**: Fit step with the given data inputs, and expected outputs.\n",
    "\n",
    "5. **[transform(data_inputs)](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base._TransformerStep.transform)**: Transform given data inputs.\n",
    "6. **[save(context, full_dump)](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base._HasSavers.save)**: Save step using the execution context to create the directory to save the step into.\n",
    "7. **[teardown()](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.TransformerStep.teardown)**: Teardown step after program execution. Inverse of setup, and it should clear memory. Override this method if you need to clear memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Neuraxle, each step has a list of savers that can load, and save steps. Steps are saved using the execution context to create the directory to save the step into. The saving happens by looping through all of the step savers in the reversed order. Each savers must inherit from [BaseSaver](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.BaseSaver).\n",
    "\n",
    "The cool thing about this is that you don't even need the source code to load your steps. This enables a lot of thing like parallel processing, and distributed computing. \n",
    "\n",
    "## Saver\n",
    "\n",
    "Some savers just save parts of objects, some save it all or what remains.\n",
    "The **[JoblibStepSaver](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.JoblibStepSaver) has to be called last** because it needs a\n",
    "stripped version of the step. You might need to create your own saver if you are using a step that is not serializable. For instance, this will most likely happen if the step is a deep learning model. \n",
    "\n",
    "Fortunately, we have already built a set of savers for tensorflow 1, and 2 in [Neuraxle-Tensorflow](https://github.com/Neuraxio/Neuraxle-TensorFlow). We plan to do the same thing for Pytorch soon.\n",
    "\n",
    "## Custom Saver Example \n",
    "\n",
    "Each step needs to be stripped of all its not serialisable parts so that the [JoblibStepSaver](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.JoblibStepSaver) (default saver) can serialize the step using joblib. Here is an example of a custom saver that strips the multiprocessing Queue from a step called [SequentialQueuedPipeline](https://www.neuraxle.org/stable/api/neuraxle.distributed.streaming.html#neuraxle.distributed.streaming.SequentialQueuedPipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.base import BaseSaver, BaseStep, ExecutionContext, Identity\n",
    "from queue import Queue\n",
    "\n",
    "class ObservableQueueStepSaver(BaseSaver):\n",
    "    def save_step(self, step: 'BaseStep', context: 'ExecutionContext') -> 'BaseStep':\n",
    "        step.queue = None\n",
    "        step.observers = []\n",
    "        return step\n",
    "\n",
    "    def can_load(self, step: 'BaseStep', context: 'ExecutionContext'):\n",
    "        return True\n",
    "\n",
    "    def load_step(self, step: 'BaseStep', context: 'ExecutionContext') -> 'BaseStep':\n",
    "        step.queue = Queue()\n",
    "        return step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then add this saver to the list of savers of any step, and it will be executed before being serialised with joblib: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityWithQueue(Identity):\n",
    "    def __init__(self):\n",
    "        super().__init__(savers=[ObservableQueueStepSaver()])\n",
    "\n",
    "    def setup(self, context=None):\n",
    "        if not self.is_initialized:\n",
    "            self.queue = Queue()\n",
    "\n",
    "        super().setup()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome ! Now, the multiprocessing.Queue object will be set to None before the [JoblibStepSaver](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.JoblibStepSaver) saves this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Example \n",
    "\n",
    "## Pipeline\n",
    "\n",
    "First, let's define a simple linear regression pipeline. Notice that we also included the IdentityWithQueue step from the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: [4 6 2 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from neuraxle.base import BaseSaver, BaseStep, NonFittableMixin, ExecutionContext\n",
    "from neuraxle.pipeline import Pipeline\n",
    "from neuraxle.steps.flow import TrainOnlyWrapper\n",
    "from neuraxle.steps.output_handlers import OutputTransformerWrapper\n",
    "from neuraxle.steps.sklearn import SKLearnWrapper\n",
    "from neuraxle.steps.data import DataShuffler\n",
    "from neuraxle.hyperparams.space import HyperparameterSamples, HyperparameterSpace\n",
    "from neuraxle.hyperparams.distributions import LogUniform, Boolean, Choice, RandInt\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "\n",
    "class NumpyRavel(NonFittableMixin, BaseStep):\n",
    "    def transform(self, data_inputs):\n",
    "        if data_inputs is None:\n",
    "            return data_inputs\n",
    "\n",
    "        data_inputs = data_inputs if isinstance(data_inputs, np.ndarray) else np.array(data_inputs)\n",
    "        return data_inputs.ravel()\n",
    "\n",
    "PIPELINE_NAME = 'saved_pipeline_name'\n",
    "cache_folder = 'cache_folder'\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    IdentityWithQueue(),\n",
    "    TrainOnlyWrapper(DataShuffler()),\n",
    "    OutputTransformerWrapper(NumpyRavel()),\n",
    "    SKLearnWrapper(LogisticRegression(), HyperparameterSpace({\n",
    "        'C': LogUniform(0.01, 10.0), \n",
    "        'fit_intercept': Boolean(), \n",
    "        'dual': Boolean(),\n",
    "        'penalty': Choice(['l1', 'l2']), \n",
    "        'max_iter': RandInt(20, 200)\n",
    "    }))\n",
    "], cache_folder=cache_folder).set_name(PIPELINE_NAME)\n",
    "\n",
    "data_inputs = np.expand_dims(np.array([0, 1, 2, 3]), axis=-1)\n",
    "expected_outputs = np.expand_dims(np.array([0, 2, 4, 6]), axis=-1)\n",
    "pipeline, outputs = pipeline.fit_transform(data_inputs, expected_outputs)\n",
    "print('outputs: {}'.format(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dump Saving\n",
    "\n",
    "Next, let's save the full pipeline even if steps are not invalidated or initialized. To do this, we need to call the save method with an [ExecutionContext](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.ExecutionContext), and the full_dump argument to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved pipeline ! \n"
     ]
    }
   ],
   "source": [
    "pipeline.save(ExecutionContext(cache_folder), full_dump=True)\n",
    "print('saved pipeline ! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cache_folder\r\n",
      "./cache_folder/saved_pipeline_name\r\n",
      "./cache_folder/saved_pipeline_name/saved_pipeline_name.joblib\r\n",
      "./cache_folder/saved_pipeline_name/TrainOnlyWrapper\r\n",
      "./cache_folder/saved_pipeline_name/TrainOnlyWrapper/DataShuffler\r\n",
      "./cache_folder/saved_pipeline_name/TrainOnlyWrapper/DataShuffler/DataShuffler.joblib\r\n",
      "./cache_folder/saved_pipeline_name/TrainOnlyWrapper/TrainOnlyWrapper.joblib\r\n",
      "./cache_folder/saved_pipeline_name/SKLearnWrapper_LogisticRegression\r\n",
      "./cache_folder/saved_pipeline_name/SKLearnWrapper_LogisticRegression/SKLearnWrapper_LogisticRegression.joblib\r\n",
      "./cache_folder/saved_pipeline_name/IdentityWithQueue\r\n",
      "./cache_folder/saved_pipeline_name/IdentityWithQueue/IdentityWithQueue.joblib\r\n",
      "./cache_folder/saved_pipeline_name/OutputTransformerWrapper\r\n",
      "./cache_folder/saved_pipeline_name/OutputTransformerWrapper/OutputTransformerWrapper.joblib\r\n",
      "./cache_folder/saved_pipeline_name/OutputTransformerWrapper/NumpyRavel\r\n",
      "./cache_folder/saved_pipeline_name/OutputTransformerWrapper/NumpyRavel/NumpyRavel.joblib\r\n"
     ]
    }
   ],
   "source": [
    "!find . | grep \"cache_folder/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dump Loading\n",
    "\n",
    "To Load a full pipeline without any source code, you can call use the [load](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.ExecutionContext.load) method from the [ExecutionContext](https://www.neuraxle.org/stable/api/neuraxle.base.html#neuraxle.base.ExecutionContext): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pipeline without any source code !\n",
      "outputs: [2 0 4 6]\n"
     ]
    }
   ],
   "source": [
    "loaded_pipeline = ExecutionContext(cache_folder).load(PIPELINE_NAME)\n",
    "print('loaded pipeline without any source code !')\n",
    "outputs = pipeline.transform(data_inputs)\n",
    "print('outputs: {}'.format(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(cache_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuraxle_notebooks",
   "language": "python",
   "name": "neuraxle_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
