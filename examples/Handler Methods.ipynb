{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handler Methods\n",
    "\n",
    "<p style=\"font-size:18px\">Handler methods structure how to handle the flow of data from one step to another. Steps can override this algorithm inherited from BaseStep to change the behavior of the flow of data. It makes it possible to build really powerful steps that can edit and change the execution flow, and in multiple dimensions. Here is the detailed reference.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/handler_methods.png\" style=\"width=:50\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following handle methods are available for each step: \n",
    "\n",
    "\n",
    "### handle_fit_transform\n",
    "\n",
    "1. _will_process(data_container, context): Apply side effects before any step method.\n",
    "2. _will_fit_transform(data_container, context): Apply side effects before fit_transform\n",
    "3. _fit_transform_data_container(data_container, context): Fit transform data container.\n",
    "4. _did_fit_transform(data_container, context): Apply side effects after fit_transform.\n",
    "5. _did_process(data_container, context): Apply side effects after any step method.\n",
    "\n",
    "### handle_fit\n",
    "\n",
    "1. _will_process(data_container, context): Apply side effects before any step method.\n",
    "2. _will_fit_transform(data_container, context): Apply side effects before fit.\n",
    "3. _fit_data_container(data_container, context): Fit data container.\n",
    "4. _did_fit(data_container, context): Apply side effects after fit.\n",
    "\n",
    "### handle_transform\n",
    "\n",
    "1. _will_process(data_container, context): Apply side effects before any step method.\n",
    "2. _will_transform(data_container, context): Apply side effects before transform.\n",
    "3. _transform_data_container(data_container, context): Fit transform data container.\n",
    "4. _did_transform(data_container, context): Apply side effects after transform. \n",
    "5. _did_process(data_container, context): Apply side effects after any step method.\n",
    "\n",
    "### When to use handler methods ? \n",
    "\n",
    "When you need to apply side effects, or change the execution flow:\n",
    "\n",
    "- Edit the DataContainer\n",
    "- Call a method on a step\n",
    "- Mini-Batching\n",
    "- Caching\n",
    "- etc.\n",
    "\n",
    "### HandleOnlyMixin\n",
    "\n",
    "Inherit from HandleOnlyMixin, to only implement the handler methods, and forbid implementing fit or transform or fit_transform without the handles.\n",
    "\n",
    "### ForceHandleMixin\n",
    "\n",
    "Inherit from ForceHandleMixin, to automatically calls handle methods in the transform, fit, and fit_transform methods. A step might have to be forced to pass through the lifecycle methods. This is true for all of the steps that can be called from the outside world. For example, you might want to transform all of the data inside the data container. \n",
    "\n",
    "### ForceHandleOnlyMixin\n",
    "\n",
    "Inherit from ForceHandleOnlyMixin to require the implementation of handler methods, AND automatically call handle methods in the transform, fit, and fit_transform methods.\n",
    "\n",
    "\n",
    "## Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToNumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.base import BaseStep, DataContainer, ExecutionContext, ForceHandleMixin, HandleOnlyMixin, TruncableSteps\n",
    "import numpy as np\n",
    "\n",
    "class ToNumpy(ForceHandleMixin, BaseStep):\n",
    "    \"\"\"\n",
    "    Convert data inputs, and expected outputs to a numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    def _will_process(self, data_container: DataContainer, context: ExecutionContext) -> (DataContainer, ExecutionContext):\n",
    "        return data_container.to_numpy(), context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Expected Outputs\n",
    "Consider a wrapper step that would transform the expected outputs instead of the data inputs.\n",
    "\n",
    "Create such a step in 4 easy steps (toudoum tish) : \n",
    "\n",
    "1. Create a step that inherits from **ForceHandleOnlyMixin**, and **MetaStepMixin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.base import ExecutionContext, BaseStep, MetaStepMixin, ForceHandleOnlyMixin\n",
    "from neuraxle.data_container import DataContainer\n",
    "from neuraxle.steps.numpy import MultiplyByN\n",
    "\n",
    "\n",
    "class OutputTransformerWrapper(ForceHandleOnlyMixin, MetaStepMixin, BaseStep):\n",
    "    def __init__(self, wrapped, cache_folder_when_no_handle=None):\n",
    "        BaseStep.__init__(self)\n",
    "        MetaStepMixin.__init__(self, wrapped)\n",
    "        ForceHandleOnlyMixin.__init__(self, cache_folder_when_no_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement **_transform_data_container**: \n",
    "\n",
    "Pass expected outputs to the wrapped step **handle_transform** method. Update the data container expected outputs with the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n",
    "    new_expected_outputs_data_container = self.wrapped.handle_transform(\n",
    "        DataContainer(\n",
    "            data_inputs=data_container.expected_outputs, \n",
    "            current_ids=data_container.current_ids, \n",
    "            expected_outputs=None\n",
    "        ), \n",
    "        context\n",
    "    )\n",
    "    data_container.set_expected_outputs(new_expected_outputs_data_container.data_inputs)\n",
    "\n",
    "    return data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement **_fit_data_container**: \n",
    "\n",
    "Pass expected outputs to the wrapped step **handle_fit** method. Update the data container expected outputs with the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_data_container(self, data_container: DataContainer, context: ExecutionContext) -> (BaseStep, DataContainer):\n",
    "    self.wrapped = self.wrapped.handle_fit(\n",
    "        DataContainer(\n",
    "            data_inputs=data_container.expected_outputs, \n",
    "            current_ids=data_container.current_ids, \n",
    "            expected_outputs=None),\n",
    "        context\n",
    "    )\n",
    "\n",
    "    return self, data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement **_fit_transform_data_container**: \n",
    "\n",
    "Pass expected outputs to the wrapped step **handle_fit_transform** method.\n",
    "Update the data container expected outputs with the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> (BaseStep, DataContainer):\n",
    "    self.wrapped, new_expected_outputs_data_container = self.wrapped.handle_fit_transform(\n",
    "        DataContainer(\n",
    "            data_inputs=data_container.expected_outputs, \n",
    "            current_ids=data_container.current_ids,\n",
    "            expected_outputs=None\n",
    "        ),\n",
    "        context\n",
    "    )\n",
    "    data_container.set_expected_outputs(new_expected_outputs_data_container.data_inputs)\n",
    "\n",
    "    return self, data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results looks like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.base import ExecutionContext, BaseStep, MetaStepMixin, ForceHandleOnlyMixin\n",
    "from neuraxle.data_container import DataContainer\n",
    "\n",
    "\n",
    "class OutputTransformerWrapper(ForceHandleOnlyMixin, MetaStepMixin, BaseStep):\n",
    "    def __init__(self, wrapped, cache_folder_when_no_handle=None):\n",
    "        BaseStep.__init__(self)\n",
    "        MetaStepMixin.__init__(self, wrapped)\n",
    "        ForceHandleOnlyMixin.__init__(self, cache_folder_when_no_handle)\n",
    "\n",
    "    def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n",
    "        new_expected_outputs_data_container = self.wrapped.handle_transform(\n",
    "            DataContainer(data_inputs=data_container.expected_outputs, current_ids=data_container.current_ids,\n",
    "                          expected_outputs=None),\n",
    "            context\n",
    "        )\n",
    "        data_container.set_expected_outputs(new_expected_outputs_data_container.data_inputs)\n",
    "\n",
    "        return data_container\n",
    "\n",
    "    def _fit_data_container(self, data_container: DataContainer, context: ExecutionContext) -> (BaseStep, DataContainer):\n",
    "        self.wrapped = self.wrapped.handle_fit(\n",
    "            DataContainer(data_inputs=data_container.expected_outputs, current_ids=data_container.current_ids,\n",
    "                          expected_outputs=None),\n",
    "            context\n",
    "        )\n",
    "\n",
    "        return self, data_container\n",
    "\n",
    "    def _fit_transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> (BaseStep, DataContainer):\n",
    "        self.wrapped, new_expected_outputs_data_container = self.wrapped.handle_fit_transform(\n",
    "            DataContainer(data_inputs=data_container.expected_outputs, current_ids=data_container.current_ids, expected_outputs=None),\n",
    "            context\n",
    "        )\n",
    "        data_container.set_expected_outputs(new_expected_outputs_data_container.data_inputs)\n",
    "\n",
    "        return self, data_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_inputs before: [0 1]\n",
      "expected_outputs before: [1 2]\n",
      "data_inputs after: [0 1]\n",
      "expected_outputs after: [2 4]\n"
     ]
    }
   ],
   "source": [
    "data_inputs = np.array([0, 1])\n",
    "expected_outputs = np.array([1, 2])\n",
    "print('data_inputs before: {}'.format(data_inputs))\n",
    "print('expected_outputs before: {}'.format(expected_outputs))\n",
    "\n",
    "step = OutputTransformerWrapper(MultiplyByN(2))\n",
    "output_data_container = step.handle_transform(\n",
    "    DataContainer(data_inputs=data_inputs, expected_outputs=expected_outputs),\n",
    "    ExecutionContext()\n",
    ")\n",
    "\n",
    "print('data_inputs after: {}'.format(output_data_container.data_inputs))\n",
    "print('expected_outputs after: {}'.format(output_data_container.expected_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand The DataContainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a typical step that expands the dimension of all the data inside the data container. ExpandDim sends the expanded data container to the wrapped step. \n",
    "ExpandDim returns the transformed expanded dim reduced to its original shape.\n",
    "\n",
    "This can be easily done in Neuraxle: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a step that inherits from MetaStepMixin, and BaseStep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuraxle.base import BaseStep, MetaStepMixin, DataContainer, ExecutionContext, Identity\n",
    "from neuraxle.data_container import ExpandedDataContainer\n",
    "import numpy as np\n",
    "\n",
    "class ExpandDim(MetaStepMixin, BaseStep):\n",
    "    def __init__(self, wrapped: BaseStep):\n",
    "        BaseStep.__init__(self)\n",
    "        MetaStepMixin.__init__(self, wrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement the _will_process lifecycle method to expand the data inside the data container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _will_process(self, data_container, context):\n",
    "    data_container, context = BaseStep._will_process(self, data_container, context)\n",
    "    return ExpandedDataContainer.create_from(data_container), context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement the _did_process lifecycle method to reduce the dimension of the data inside the data container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _did_process(self, data_container, context):\n",
    "    data_container = BaseStep._did_process(self, data_container, context)\n",
    "    return data_container.reduce_dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result looks like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandDim(MetaStepMixin, BaseStep):\n",
    "    def __init__(self, wrapped: BaseStep):\n",
    "        BaseStep.__init__(self)\n",
    "        MetaStepMixin.__init__(self, wrapped)\n",
    "        \n",
    "    def _will_process(self, data_container, context):\n",
    "        data_container, context = BaseStep._will_process(self, data_container, context)\n",
    "        return ExpandedDataContainer.create_from(data_container), context\n",
    "\n",
    "    def _did_process(self, data_container, context):\n",
    "        data_container = BaseStep._did_process(self, data_container, context)\n",
    "        return data_container.reduce_dim()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before testing the step, let's define a quick utility class to print data for this example, and the ones after :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintData(Identity):   \n",
    "    def __init__(self, message):\n",
    "        super().__init__()\n",
    "        self.message = message\n",
    "        \n",
    "    def _did_process(self, data_container, context):\n",
    "        print('data_inputs {}: {}'.format(self.message, data_container.data_inputs))\n",
    "        print('expected_outputs {}: {}'.format(self.message, data_container.expected_outputs))\n",
    "        print('\\n')\n",
    "        return data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's transform our step :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_inputs before: [0 1]\n",
      "expected_outputs before: [1 2]\n",
      "data_inputs inside: [array([0, 1])]\n",
      "expected_outputs inside: [array([1, 2])]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    data_inputs = np.array([0, 1])\n",
    "expected_outputs = np.array([1, 2])\n",
    "print('data_inputs before: {}'.format(data_inputs))\n",
    "print('expected_outputs before: {}'.format(expected_outputs))\n",
    "\n",
    "step = ExpandDim(PrintData('inside'))\n",
    "output_data_container = step.handle_transform(\n",
    "    DataContainer(data_inputs=data_inputs, expected_outputs=expected_outputs),\n",
    "    ExecutionContext()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversible Pipeline\n",
    "\n",
    "Consider a step that can be reversible. For example, you might want to unnormalize predictions. This can be easily done with a step that inherits from TruncableSteps, and HandleOnlyMixin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a step that inherits from HandleOnlyMixin, and TruncableSteps. Initialize TruncableSteps with a preprocessing, and a postprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversiblePreprocessingWrapper(HandleOnlyMixin, TruncableSteps):\n",
    "    def __init__(self, preprocessing_step, postprocessing_step):\n",
    "        HandleOnlyMixin.__init__(self)\n",
    "        TruncableSteps.__init__(self, [\n",
    "            (\"preprocessing_step\", preprocessing_step),\n",
    "            (\"postprocessing_step\", postprocessing_step)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement _fit_data_container: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_data_container(self, data_container: DataContainer, context: ExecutionContext) -> 'ReversiblePreprocessingWrapper':\n",
    "    self[\"preprocessing_step\"], data_container = \\\n",
    "        self[\"preprocessing_step\"].handle_fit_transform(data_container, context)\n",
    "    self[\"postprocessing_step\"] = \\\n",
    "        self[\"postprocessing_step\"].handle_fit(data_container, context)\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement _transform_data_container: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n",
    "    data_container = self[\"preprocessing_step\"].handle_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"preprocessing_step\"])\n",
    "    )\n",
    "    data_container = self[\"postprocessing_step\"].handle_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"postprocessing_step\"])\n",
    "    )\n",
    "\n",
    "    data_container = self[\"preprocessing_step\"].handle_inverse_transform(\n",
    "        data_container, \n",
    "        context.push(self[\"preprocessing_step\"])\n",
    "    )\n",
    "\n",
    "    return data_container\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implement _fit_transform_data_container: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> ('BaseStep', DataContainer):\n",
    "    self[\"preprocessing_step\"], data_container = self[\"preprocessing_step\"].handle_fit_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"preprocessing_step\"])\n",
    "    )\n",
    "    self[\"postprocessing_step\"], data_container = self[\"postprocessing_step\"].handle_fit_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"postprocessing_step\"])\n",
    "    )\n",
    "\n",
    "    data_container = self[\"preprocessing_step\"].handle_inverse_transform(\n",
    "        data_container,\n",
    "        context.push(self[\"preprocessing_step\"])\n",
    "    )\n",
    "\n",
    "    return self, data_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_inputs before reversible preprocessing wrapper: [1 2]\n",
      "expected_outputs before reversible preprocessing wrapper: [None, None]\n",
      "\n",
      "\n",
      "data_inputs after preprocessing: [2 4]\n",
      "expected_outputs after preprocessing: [None, None]\n",
      "\n",
      "\n",
      "data_inputs after postprocessing: [ 6 12]\n",
      "expected_outputs after postprocessing: [None, None]\n",
      "\n",
      "\n",
      "data_inputs after preprocessing: [ 6 12]\n",
      "expected_outputs after preprocessing: [None, None]\n",
      "\n",
      "\n",
      "data inputs after inverse transform preprocessing: [3. 6.]\n"
     ]
    }
   ],
   "source": [
    "from neuraxle.pipeline import Pipeline \n",
    "from neuraxle.steps.numpy import MultiplyByN\n",
    "\n",
    "\n",
    "class ReversiblePreprocessingWrapper(HandleOnlyMixin, TruncableSteps):\n",
    "    def __init__(self, preprocessing_step, postprocessing_step):\n",
    "        HandleOnlyMixin.__init__(self)\n",
    "        TruncableSteps.__init__(self, [\n",
    "            (\"preprocessing_step\", preprocessing_step),\n",
    "            (\"postprocessing_step\", postprocessing_step)\n",
    "        ])\n",
    "        \n",
    "    def _fit_transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> ('BaseStep', DataContainer):\n",
    "        self[\"preprocessing_step\"], data_container = self[\"preprocessing_step\"].handle_fit_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"preprocessing_step\"])\n",
    "        )\n",
    "        self[\"postprocessing_step\"], data_container = self[\"postprocessing_step\"].handle_fit_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"postprocessing_step\"])\n",
    "        )\n",
    "\n",
    "        data_container = self[\"preprocessing_step\"].handle_inverse_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"preprocessing_step\"])\n",
    "        )\n",
    "\n",
    "        return self, data_container\n",
    "\n",
    "    def _transform_data_container(self, data_container: DataContainer, context: ExecutionContext) -> DataContainer:\n",
    "        data_container = self[\"preprocessing_step\"].handle_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"preprocessing_step\"])\n",
    "        )\n",
    "        data_container = self[\"postprocessing_step\"].handle_transform(\n",
    "            data_container,\n",
    "            context.push(self[\"postprocessing_step\"])\n",
    "        )\n",
    "\n",
    "        data_container = self[\"preprocessing_step\"].handle_inverse_transform(\n",
    "            data_container, \n",
    "            context.push(self[\"preprocessing_step\"])\n",
    "        )\n",
    "\n",
    "        return data_container\n",
    "\n",
    "    def _fit_data_container(self, data_container: DataContainer, context: ExecutionContext) -> 'ReversiblePreprocessingWrapper':\n",
    "        self[\"preprocessing_step\"], data_container = \\\n",
    "            self[\"preprocessing_step\"].handle_fit_transform(data_container, context)\n",
    "        self[\"postprocessing_step\"] = \\\n",
    "            self[\"postprocessing_step\"].handle_fit(data_container, context)\n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "data_inputs = np.array([1, 2])\n",
    "\n",
    "p = Pipeline([\n",
    "    PrintData('before reversible preprocessing wrapper'),\n",
    "    ReversiblePreprocessingWrapper(\n",
    "        preprocessing_step=Pipeline([\n",
    "            MultiplyByN(2),\n",
    "            PrintData('after preprocessing')\n",
    "        ]),\n",
    "        postprocessing_step=Pipeline([\n",
    "            MultiplyByN(3),\n",
    "            PrintData('after postprocessing')\n",
    "        ])\n",
    "    )\n",
    "])\n",
    "\n",
    "outputs = p.transform(data_inputs)\n",
    "print('data inputs after inverse transform preprocessing: {}'.format(outputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks_neuraxle",
   "language": "python",
   "name": "notebooks_neuraxle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
